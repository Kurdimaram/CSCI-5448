{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Graduate Presentation__<br>\n",
    "CSCI 5448 (Object-Oriented Analysis & Design)<br>\n",
    "__Maram Kurdi__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Toolkit (NLTK) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will ask the user to enter a text in order to preprocess it for nay NLP tasks<br>\n",
    "**Text preprocessing include:**\n",
    "* Sentence Tokenization\n",
    "* Word Tokenization\n",
    "* Removing Stopwords\n",
    "* Removing Punctuation\n",
    "* Stemming\n",
    "* Lemmatization\n",
    "* Part of Speech Tagging\n",
    "* Frequency Distribution\n",
    "* Chunking\n",
    "* Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to process:\n",
      "Natural language processing NLP is a subfield of computer science, information engineering, and artificial intelligence. It concerned with the interactions between computers and human natural languages, in particular how to program computers to process and analyze large amounts of natural language data.  I like to use Python. I hate coding with Java.\n"
     ]
    }
   ],
   "source": [
    "# get user text input\n",
    "user_text = input(\"Enter text to process:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sentence Tokenization\n",
    "Sentence tokenizer breaks text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing NLP is a subfield of computer science, information engineering, and artificial intelligence.', 'It concerned with the interactions between computers and human natural languages, in particular how to program computers to process and analyze large amounts of natural language data.', 'I like to use Python.', 'I hate coding with Java.']\n",
      "Number of sentences:  4\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(user_text)\n",
    "print(sentences)\n",
    "print(\"Number of sentences: \",len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word Tokenization\n",
    "Word tokenizer breaks sentences into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'NLP', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', '.', 'It', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'natural', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.', 'I', 'like', 'to', 'use', 'Python', '.', 'I', 'hate', 'coding', 'with', 'Java', '.']\n",
      "Number of words:  59\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(user_text)\n",
    "print(words)\n",
    "print(\"Number of words: \",len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Removing Stopwords and Punctuation\n",
    "Removing Stopwords from text that don't give meaning such as (the, a, this, etc)<br>\n",
    "Removing punctuation from text such as ( .  ,  ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'NLP', 'subfield', 'computer', 'science', 'information', 'engineering', 'artificial', 'intelligence', 'It', 'concerned', 'interactions', 'computers', 'human', 'natural', 'languages', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', 'I', 'like', 'use', 'Python', 'I', 'hate', 'coding', 'Java']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "filtered_panct = tokenizer.tokenize(user_text) # remove punctuation\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_text = [i for i in filtered_panct if not i in stop_words] # remove stopwords\n",
    "print (filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stemming using PorterStemmer\n",
    "Stemming means reducing inflected words to their word stem, base or root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'nlp', 'subfield', 'comput', 'scienc', 'inform', 'engin', 'artifici', 'intellig', 'It', 'concern', 'interact', 'comput', 'human', 'natur', 'languag', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', 'I', 'like', 'use', 'python', 'I', 'hate', 'code', 'java']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_text = [stemmer.stem(word) for word in filtered_text] # stemming words\n",
    "print (stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Lemmatization\n",
    "Lemmatization is the process of removing inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'process', 'NLP', 'subfield', 'computer', 'science', 'information', 'engineer', 'artificial', 'intelligence', 'It', 'concern', 'interactions', 'computers', 'human', 'natural', 'languages', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'data', 'I', 'like', 'use', 'Python', 'I', 'hate', 'cod', 'Java']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "Lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_text = [Lemmatizer.lemmatize(word,\"v\") for word in filtered_text] # Lemmatizing words\n",
    "print (lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Part of Speech Tagging\n",
    "is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('NLP', 'NNP'), ('subfield', 'VBD'), ('computer', 'NN'), ('science', 'NN'), ('information', 'NN'), ('engineering', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('It', 'PRP'), ('concerned', 'VBD'), ('interactions', 'NNS'), ('computers', 'NNS'), ('human', 'JJ'), ('natural', 'JJ'), ('languages', 'NNS'), ('particular', 'JJ'), ('program', 'NN'), ('computers', 'NNS'), ('process', 'VBP'), ('analyze', 'JJ'), ('large', 'JJ'), ('amounts', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('I', 'PRP'), ('like', 'VBP'), ('use', 'IN'), ('Python', 'NNP'), ('I', 'PRP'), ('hate', 'VBP'), ('coding', 'VBG'), ('Java', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "Part_of_Speech = nltk.pos_tag(filtered_text)\n",
    "print (Part_of_Speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Chunking \n",
    "Chunking is a task that follows Part-Of-Speech Tagging and that adds more structure to the sentence. The result is a grouping of the words in “chunks”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Natural/JJ language/NN)\n",
      "  (NP processing/NN)\n",
      "  NLP/NNP\n",
      "  subfield/VBD\n",
      "  (NP computer/NN)\n",
      "  (NP science/NN)\n",
      "  (NP information/NN)\n",
      "  (NP engineering/NN)\n",
      "  (NP artificial/JJ intelligence/NN)\n",
      "  It/PRP\n",
      "  concerned/VBD\n",
      "  interactions/NNS\n",
      "  computers/NNS\n",
      "  human/JJ\n",
      "  natural/JJ\n",
      "  languages/NNS\n",
      "  (NP particular/JJ program/NN)\n",
      "  computers/NNS\n",
      "  process/VBP\n",
      "  analyze/JJ\n",
      "  large/JJ\n",
      "  amounts/NNS\n",
      "  (NP natural/JJ language/NN)\n",
      "  data/NNS\n",
      "  I/PRP\n",
      "  like/VBP\n",
      "  use/IN\n",
      "  Python/NNP\n",
      "  I/PRP\n",
      "  hate/VBP\n",
      "  coding/VBG\n",
      "  Java/NNP)\n"
     ]
    }
   ],
   "source": [
    "reg_exp = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "rp = nltk.RegexpParser(reg_exp)\n",
    "chunked = rp.parse(Part_of_Speech)\n",
    "print(chunked)\n",
    "chunked.draw() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Frequency Distribution\n",
    "Counting the occurrence for each word for giving text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('language', 2), ('computers', 2), ('natural', 2), ('I', 2), ('Natural', 1), ('processing', 1), ('NLP', 1), ('subfield', 1), ('computer', 1), ('science', 1), ('information', 1), ('engineering', 1), ('artificial', 1), ('intelligence', 1), ('It', 1), ('concerned', 1), ('interactions', 1), ('human', 1), ('languages', 1), ('particular', 1), ('program', 1), ('process', 1), ('analyze', 1), ('large', 1), ('amounts', 1), ('data', 1), ('like', 1), ('use', 1), ('Python', 1), ('hate', 1), ('coding', 1), ('Java', 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "word_freq = FreqDist(filtered_text)\n",
    "print(word_freq.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Sentiment Analysis\n",
    "Sentiment Analysis is the process of computationally identifying and categorizing opinions expressed in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing NLP is a subfield of computer science, information engineering, and artificial intelligence.\n",
      "neg: 0.0, neu: 0.682, pos: 0.318, compound: 0.6808, \n",
      "It concerned with the interactions between computers and human natural languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
      "neg: 0.0, neu: 0.833, pos: 0.167, compound: 0.6124, \n",
      "I like to use Python.\n",
      "neg: 0.0, neu: 0.545, pos: 0.455, compound: 0.3612, \n",
      "I hate coding with Java.\n",
      "neg: 0.552, neu: 0.448, pos: 0.0, compound: -0.5719, \n"
     ]
    }
   ],
   "source": [
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "     print(sentence)\n",
    "     ss = sentiment.polarity_scores(sentence)\n",
    "     for k in ss:\n",
    "         print(\"{0}: {1}, \".format(k, ss[k]), end=\"\")\n",
    "     print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
